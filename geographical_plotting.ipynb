{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f0d041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be2ae221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading dataset\n",
    "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d9bc6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oxford, MS                  27\n",
       "United States               24\n",
       "Columbia, SC, USA           17\n",
       "Ballarat, Victoria          16\n",
       "Washington, DC              15\n",
       "Memphis, TN                 14\n",
       "California                  14\n",
       "London, England             13\n",
       "Pittsburgh                  12\n",
       "Lafayette, CO               10\n",
       "Oakland, CA                  9\n",
       "Fayetteville, Arkansas       9\n",
       "California, USA              8\n",
       "Atlanta, GA                  7\n",
       "San Francisco, CA            7\n",
       "New York, NY                 7\n",
       "Canada                       7\n",
       "Anaheim, CA                  7\n",
       "Reston, VA                   7\n",
       "Dallas, TX                   6\n",
       "South Carolina, USA          6\n",
       "Brownsville, TX              5\n",
       "Iowa and Colorado            5\n",
       "LI, NY                       5\n",
       "Tigard, OR                   5\n",
       "Probabilium                  5\n",
       "Probabilium                  5\n",
       "Oklahoma City, OK            5\n",
       "London                       5\n",
       "U.S.                         5\n",
       "USA                          5\n",
       "Boston, MA                   5\n",
       "Beaverton, OR                4\n",
       "Global                       4\n",
       "Chicago, IL                  4\n",
       "Georgia                      4\n",
       "Tampa, FL                    4\n",
       "Toronto, Ontario             4\n",
       "Cambridge, MA                4\n",
       "Sheikh Zayed City, Egypt     4\n",
       "Los Angeles                  4\n",
       "Fremont, CA                  4\n",
       "New Hampshire                4\n",
       "Toronto/Valencia             4\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locs = tweets_df['location'].value_counts()\n",
    "locs[locs>=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "947825dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-72372f6a1482>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeocoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mlat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'geometry'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mlong\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'geometry'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lng'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mlatitudes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from opencage.geocoder import OpenCageGeocode\n",
    "key = \"820eed38aaf449a5b4828c0fad8d1501\"\n",
    "geocoder = OpenCageGeocode(key)\n",
    "\n",
    "def isNaN(string):\n",
    "    return string != string\n",
    "\n",
    "latitudes=[]\n",
    "longitudes=[]\n",
    "\n",
    "for l in tweets_df[\"location\"]:\n",
    "    if isNaN(l):\n",
    "        latitudes.append(np.nan)\n",
    "        longitudes.append(np.nan)\n",
    "    else:\n",
    "        results = geocoder.geocode(query)\n",
    "        lat = results[0]['geometry']['lat']\n",
    "        long = results[0]['geometry']['lng']\n",
    "        latitudes.append(lat)\n",
    "        longitudes.append(long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ec3d9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5dad08f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " nan,\n",
       " -1.9203562,\n",
       " -1.9203562,\n",
       " -1.9203562]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15fa71f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/1:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from jupyterthemes import jtplot\n",
      "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
      "# setting the style of the notebook to be monokai theme  \n",
      "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
      "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n",
      " 2/2:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from jupyterthemes import jtplot\n",
      "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
      "# setting the style of the notebook to be monokai theme  \n",
      "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
      "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n",
      " 2/3:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from jupyterthemes import jtplot\n",
      "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
      "# setting the style of the notebook to be monokai theme  \n",
      "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
      "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n",
      " 2/4: tweets_df = pd.read_json(\"C:/Users/nic/Documents/OUR_Project/Code/Twitter/edtweets.json\", lines=True)\n",
      " 2/5: tweets_df\n",
      " 2/6: tweets_df\n",
      " 2/7: tweets_df.info()\n",
      " 2/8: tweets_df.describe()\n",
      " 2/9: tweets_df['text']\n",
      "2/10: tweets_df\n",
      "2/11: tweets_df = tweets_df.drop(['display_text_range'],axis=1)\n",
      "2/12: tweets_df\n",
      "2/13: sns.heatmap(tweets_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n",
      "2/14:\n",
      "# Let's get the length of the messages\n",
      "tweets_df['length'] = tweets_df['text'].apply(len)\n",
      "2/15: tweets_df\n",
      "2/16: tweets_df['length'].plot(bins=100, kind='hist')\n",
      "2/17: tweets_df.describe()\n",
      "2/18:\n",
      "# Let's see the shortest message \n",
      "tweets_df[tweets_df['length'] == 1]['text'].iloc[0]\n",
      "2/19: tweets_df.describe()\n",
      "2/20: tweets_df[tweets_df['length'] == 118]['text'].iloc[0]\n",
      "2/21: sentences = tweets_df['text'].tolist()\n",
      "2/22: sentences\n",
      "2/23: len(sentences)\n",
      "2/24: sentences_as_one_string = \" \".join(sentences)\n",
      "2/25:\n",
      "!pip install WordCloud\n",
      "from wordcloud import WordCloud\n",
      "\n",
      "plt.figure(figsize=(10,10))\n",
      "plt.imshow(WordCloud().generate(sentences_as_one_string))\n",
      "2/26:\n",
      "import string\n",
      "string.punctuation\n",
      "2/27: Test = 'Good morning beautiful people :)... I am having fun learning Machine learning and AI!!'\n",
      "2/28:\n",
      "Test_punc_removed= []\n",
      "\n",
      "for char in Test:\n",
      "    if char not in string.punctuation:\n",
      "        Test_punc_removed.append(char)\n",
      "2/29:\n",
      "# Join the characters again to form the string.\n",
      "Test_punc_removed_combined = ' '.join(Test_punc_removed)\n",
      "Test_punc_removed_combined\n",
      "2/30:\n",
      "import nltk # Natural Language tool kit \n",
      "\n",
      "nltk.download('stopwords')\n",
      "2/31:\n",
      "# You have to download stopwords Package to execute this command\n",
      "from nltk.corpus import stopwords\n",
      "stopwords.words('english')\n",
      "2/32: from sklearn.feature_extraction.text import CountVectorizer\n",
      "2/33:\n",
      "# Let's define a pipeline to clean up all the messages \n",
      "# The pipeline performs the following: (1) remove punctuation, (2) remove stopwords\n",
      "\n",
      "def message_cleaning(message):\n",
      "    Test_punc_removed = [char for char in message if char not in string.punctuation]\n",
      "    Test_punc_removed_join = ''.join(Test_punc_removed)\n",
      "    Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords.words('english')]\n",
      "    return Test_punc_removed_join_clean\n",
      "2/34:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from jupyterthemes import jtplot\n",
      "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
      "# setting the style of the notebook to be monokai theme  \n",
      "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
      "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n",
      "2/35: tweets_df = pd.read_json(\"C:/Users/nic/Documents/OUR_Project/Code/Twitter/edtweets.json\", lines=True)\n",
      "2/36: tweets_df\n",
      "2/37: tweets_df.info()\n",
      "2/38: tweets_df.describe()\n",
      "2/39: tweets_df['text']\n",
      "2/40: tweets_df\n",
      "2/41: tweets_df = tweets_df.drop(['display_text_range'],axis=1)\n",
      "2/42: tweets_df\n",
      "2/43: sns.heatmap(tweets_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n",
      "2/44:\n",
      "# Let's get the length of the messages\n",
      "tweets_df['length'] = tweets_df['text'].apply(len)\n",
      "2/45: tweets_df\n",
      "2/46: tweets_df['length'].plot(bins=100, kind='hist')\n",
      "2/47: tweets_df.describe()\n",
      "2/48: sentences = tweets_df['text'].tolist()\n",
      "2/49: sentences\n",
      "2/50: len(sentences)\n",
      "2/51: sentences_as_one_string = \" \".join(sentences)\n",
      "2/52:\n",
      "!pip install WordCloud\n",
      "from wordcloud import WordCloud\n",
      "\n",
      "plt.figure(figsize=(10,10))\n",
      "plt.imshow(WordCloud().generate(sentences_as_one_string))\n",
      "2/53:\n",
      "import string\n",
      "string.punctuation\n",
      "2/54: Test = 'Good morning beautiful people :)... I am having fun learning Machine learning and AI!!'\n",
      "2/55:\n",
      "Test_punc_removed= []\n",
      "\n",
      "for char in Test:\n",
      "    if char not in string.punctuation:\n",
      "        Test_punc_removed.append(char)\n",
      "2/56:\n",
      "# Join the characters again to form the string.\n",
      "Test_punc_removed_combined = ' '.join(Test_punc_removed)\n",
      "Test_punc_removed_combined\n",
      "2/57:\n",
      "import nltk # Natural Language tool kit \n",
      "\n",
      "nltk.download('stopwords')\n",
      "2/58:\n",
      "# You have to download stopwords Package to execute this command\n",
      "from nltk.corpus import stopwords\n",
      "stopwords.words('english')\n",
      "2/59: from sklearn.feature_extraction.text import CountVectorizer\n",
      "2/60: from sklearn.feature_extraction.text import CountVectorizer\n",
      "2/61:\n",
      "# Let's define a pipeline to clean up all the messages \n",
      "# The pipeline performs the following: (1) remove punctuation, (2) remove stopwords\n",
      "\n",
      "def message_cleaning(message):\n",
      "    Test_punc_removed = [char for char in message if char not in string.punctuation]\n",
      "    Test_punc_removed_join = ''.join(Test_punc_removed)\n",
      "    Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords.words('english')]\n",
      "    return Test_punc_removed_join_clean\n",
      "2/62:\n",
      "# Let's test the newly added function\n",
      "tweets_df_clean = tweets_df['text'].apply(message_cleaning)\n",
      "2/63: print(tweets_df_clean[5]) # show the cleaned up version\n",
      "2/64: print(tweets_df['text'][5]) # show the original version\n",
      "2/65:\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "# Define the cleaning pipeline we defined earlier\n",
      "vectorizer = CountVectorizer(analyzer = message_cleaning, dtype = 'uint8')\n",
      "tweets_countvectorizer = vectorizer.fit_transform(tweets_df['text'])\n",
      "2/66: print(vectorizer.get_feature_names())\n",
      "2/67: print(tweets_countvectorizer.toarray())\n",
      "2/68: tweets_countvectorizer.shape\n",
      "2/69: tweets = pd.DataFrame(tweets_countvectorizer.toarray())\n",
      "2/70: X = tweets\n",
      "2/71: X\n",
      "2/72: X.shape\n",
      "2/73: y.shape\n",
      "2/74:\n",
      "from sklearn.model_selection import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
      "2/75:\n",
      "# Let's define a pipeline to clean up all the messages \n",
      "# The pipeline performs the following: (1) remove punctuation, (2) remove stopwords\n",
      "\n",
      "def message_cleaning(message):\n",
      "    Test_punc_removed = [char for char in message if char not in string.punctuation]\n",
      "    Test_punc_removed_join = ''.join(Test_punc_removed)\n",
      "    Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords.words('english')]\n",
      "    return Test_punc_removed_join_clean\n",
      "2/76:\n",
      "# Let's test the newly added function\n",
      "tweets_df_clean = tweets_df['text'].apply(message_cleaning)\n",
      "2/77: print(tweets_df_clean[5]) # show the cleaned up version\n",
      "2/78: print(tweets_df['text'][5]) # show the original version\n",
      "2/79:\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "# Define the cleaning pipeline we defined earlier\n",
      "vectorizer = CountVectorizer(analyzer = message_cleaning, dtype = 'uint8')\n",
      "tweets_countvectorizer = vectorizer.fit_transform(tweets_df['text'])\n",
      "2/80: print(vectorizer.get_feature_names())\n",
      "2/81: print(tweets_countvectorizer.toarray())\n",
      "2/82: tweets_countvectorizer.shape\n",
      "2/83: tweets = pd.DataFrame(tweets_countvectorizer.toarray())\n",
      "2/84: X = tweets\n",
      "2/85: X\n",
      "2/86: X.shape\n",
      " 4/1:\n",
      "import json\n",
      "import csv\n",
      "import tweepy\n",
      "import re\n",
      " 4/2:\n",
      "\"\"\"\n",
      "INPUTS:\n",
      "    consumer_key, consumer_secret, access_token, access_token_secret: codes \n",
      "    telling twitter that we are authorized to access this data\n",
      "    hashtag_phrase: the combination of hashtags to search for\n",
      "OUTPUTS:\n",
      "    none, simply save the tweet info to a spreadsheet\n",
      "\"\"\"\n",
      "def search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase):\n",
      "    \n",
      "    #create authentication for accessing Twitter\n",
      "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "    auth.set_access_token(access_token, access_token_secret)\n",
      "\n",
      "    #initialize Tweepy API\n",
      "    api = tweepy.API(auth)\n",
      "    \n",
      "    #get the name of the spreadsheet we will write to\n",
      "    fname = '_'.join(re.findall(r\"#(\\w+)\", hashtag_phrase))\n",
      "\n",
      "    #open the spreadsheet we will write to\n",
      "    with open('%s.csv' % (fname), 'wb') as file:\n",
      "\n",
      "        w = csv.writer(file)\n",
      "\n",
      "        #write header row to spreadsheet\n",
      "        w.writerow(['timestamp', 'tweet_text', 'username', 'all_hashtags', 'followers_count'])\n",
      "\n",
      "        #for each tweet matching our hashtags, write relevant info to the spreadsheet\n",
      "        for tweet in tweepy.Cursor(api.search, q=hashtag_phrase+' -filter:retweets', \\\n",
      "                                   lang=\"en\", tweet_mode='extended').items(100):\n",
      "            w.writerow([tweet.created_at, tweet.full_text.replace('\\n',' ').encode('utf-8'), tweet.user.screen_name.encode('utf-8'), [e['text'] for e in tweet._json['entities']['hashtags']], tweet.user.followers_count])\n",
      " 4/3:\n",
      "consumer_key = raw_input('EGxDfDulxJP9oHGbkwkAzNSBK')\n",
      "consumer_secret = raw_input('0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD')\n",
      "access_token = raw_input('2854813381-EDVXKiR6Jw3aqw6EXJI24eQ7OTu8NVek6652sBN')\n",
      "access_token_secret = raw_input('0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD')\n",
      "    \n",
      "hashtag_phrase = raw_input('Hashtag Phrase ')\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n",
      " 4/4:\n",
      "consumer_key = 'EGxDfDulxJP9oHGbkwkAzNSBK'\n",
      "consumer_secret = '0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD'\n",
      "access_token = '2854813381-EDVXKiR6Jw3aqw6EXJI24eQ7OTu8NVek6652sBN'\n",
      "access_token_secret = '0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD'\n",
      "    \n",
      "hashtag_phrase = raw_input('edchat')\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n",
      " 4/5:\n",
      "consumer_key = 'EGxDfDulxJP9oHGbkwkAzNSBK'\n",
      "consumer_secret = '0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD'\n",
      "access_token = '2854813381-EDVXKiR6Jw3aqw6EXJI24eQ7OTu8NVek6652sBN'\n",
      "access_token_secret = '0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD'\n",
      "    \n",
      "hashtag_phrase = 'edchat'\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n",
      " 4/6:\n",
      "\"\"\"\n",
      "INPUTS:\n",
      "    consumer_key, consumer_secret, access_token, access_token_secret: codes \n",
      "    telling twitter that we are authorized to access this data\n",
      "    hashtag_phrase: the combination of hashtags to search for\n",
      "OUTPUTS:\n",
      "    none, simply save the tweet info to a spreadsheet\n",
      "\"\"\"\n",
      "def search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase):\n",
      "    \n",
      "    #create authentication for accessing Twitter\n",
      "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "    auth.set_access_token(access_token, access_token_secret)\n",
      "\n",
      "    #initialize Tweepy API\n",
      "    api = tweepy.API(auth)\n",
      "    \n",
      "    #get the name of the spreadsheet we will write to\n",
      "    fname = '_'.join(re.findall(r\"#(\\w+)\", hashtag_phrase))\n",
      "\n",
      "    #open the spreadsheet we will write to\n",
      "    with open('%s.csv' % (fname), 'wb') as file:\n",
      "\n",
      "        w = csv.writer(file)\n",
      "\n",
      "        #write header row to spreadsheet\n",
      "        w.writerow(['timestamp', 'tweet_text', 'username', 'all_hashtags', 'followers_count'])\n",
      "\n",
      "        #for each tweet matching our hashtags, write relevant info to the spreadsheet\n",
      "        for tweet in tweepy.Cursor(api.search, q=hashtag_phrase+' -filter:retweets', \\\n",
      "                                   lang=\"en\", tweet_mode='extended').items(100):\n",
      "            w.writerow([tweet.created_at, tweet.full_text.replace('\\n',' ').encode('utf-8'), tweet.user.screen_name.encode('utf-8'), [e['text'] for e in tweet._json['entities']['hashtags']], tweet.user.followers_count])\n",
      " 4/7:\n",
      "consumer_key = raw_input('EGxDfDulxJP9oHGbkwkAzNSBK')\n",
      "consumer_secret = '0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD'\n",
      "access_token = '2854813381-EDVXKiR6Jw3aqw6EXJI24eQ7OTu8NVek6652sBN'\n",
      "access_token_secret = '0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD'\n",
      "    \n",
      "hashtag_phrase = 'edchat'\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n",
      " 4/8:\n",
      "consumer_key = input('EGxDfDulxJP9oHGbkwkAzNSBK')\n",
      "consumer_secret = '0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD'\n",
      "access_token = '2854813381-EDVXKiR6Jw3aqw6EXJI24eQ7OTu8NVek6652sBN'\n",
      "access_token_secret = '0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD'\n",
      "    \n",
      "hashtag_phrase = 'edchat'\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n",
      " 4/9:\n",
      "import json\n",
      "import csv\n",
      "import tweepy\n",
      "import re\n",
      "4/10:\n",
      "\"\"\"\n",
      "INPUTS:\n",
      "    consumer_key, consumer_secret, access_token, access_token_secret: codes \n",
      "    telling twitter that we are authorized to access this data\n",
      "    hashtag_phrase: the combination of hashtags to search for\n",
      "OUTPUTS:\n",
      "    none, simply save the tweet info to a spreadsheet\n",
      "\"\"\"\n",
      "def search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase):\n",
      "    \n",
      "    #create authentication for accessing Twitter\n",
      "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "    auth.set_access_token(access_token, access_token_secret)\n",
      "\n",
      "    #initialize Tweepy API\n",
      "    api = tweepy.API(auth)\n",
      "    \n",
      "    #get the name of the spreadsheet we will write to\n",
      "    fname = '_'.join(re.findall(r\"#(\\w+)\", hashtag_phrase))\n",
      "\n",
      "    #open the spreadsheet we will write to\n",
      "    with open('%s.csv' % (fname), 'wb') as file:\n",
      "\n",
      "        w = csv.writer(file)\n",
      "\n",
      "        #write header row to spreadsheet\n",
      "        w.writerow(['timestamp', 'tweet_text', 'username', 'all_hashtags', 'followers_count'])\n",
      "\n",
      "        #for each tweet matching our hashtags, write relevant info to the spreadsheet\n",
      "        for tweet in tweepy.Cursor(api.search, q=hashtag_phrase+' -filter:retweets', \\\n",
      "                                   lang=\"en\", tweet_mode='extended').items(100):\n",
      "            w.writerow([tweet.created_at, tweet.full_text.replace('\\n',' ').encode('utf-8'), tweet.user.screen_name.encode('utf-8'), [e['text'] for e in tweet._json['entities']['hashtags']], tweet.user.followers_count])\n",
      "4/11:\n",
      "consumer_key = input('Consumer Key ')\n",
      "consumer_secret = input('Consumer Secret ')\n",
      "access_token = input('Access Token ')\n",
      "access_token_secret = input('Access Token Secret ')\n",
      "    \n",
      "hashtag_phrase = input('Hashtag Phrase ')\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n",
      "4/12:\n",
      "consumer_key = \"EGxDfDulxJP9oHGbkwkAzNSBK\"\n",
      "consumer_secret = \"BET032qvU4Z2UOUjflTbChdpqep60jHopjkGtVEycLhofKQSPx\"\n",
      "access_token = \"2854813381-EDVXKiR6Jw3aqw6EXJI24eQ7OTu8NVek6652sBN\"\n",
      "access_token_secret = \"0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD\"\n",
      "    \n",
      "hashtag_phrase = input('Hashtag Phrase ')\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n",
      "4/13:\n",
      "consumer_key = \"EGxDfDulxJP9oHGbkwkAzNSBK\"\n",
      "consumer_secret = \"BET032qvU4Z2UOUjflTbChdpqep60jHopjkGtVEycLhofKQSPx\"\n",
      "access_token = \"2854813381-EDVXKiR6Jw3aqw6EXJI24eQ7OTu8NVek6652sBN\"\n",
      "access_token_secret = \"0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD\"\n",
      "    \n",
      "hashtag_phrase = input('Hashtag Phrase ')\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n",
      "4/14:\n",
      "consumer_key = \"EGxDfDulxJP9oHGbkwkAzNSBK\"\n",
      "consumer_secret = \"BET032qvU4Z2UOUjflTbChdpqep60jHopjkGtVEycLhofKQSPx\"\n",
      "access_token = \"2854813381-EDVXKiR6Jw3aqw6EXJI24eQ7OTu8NVek6652sBN\"\n",
      "access_token_secret = \"0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD\"\n",
      "    \n",
      "hashtag_phrase = \"edchat\"\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n",
      "4/15:\n",
      "\"\"\"\n",
      "INPUTS:\n",
      "    consumer_key, consumer_secret, access_token, access_token_secret: codes \n",
      "    telling twitter that we are authorized to access this data\n",
      "    hashtag_phrase: the combination of hashtags to search for\n",
      "OUTPUTS:\n",
      "    none, simply save the tweet info to a spreadsheet\n",
      "\"\"\"\n",
      "def search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase):\n",
      "    \n",
      "    #create authentication for accessing Twitter\n",
      "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "    auth.set_access_token(access_token, access_token_secret)\n",
      "\n",
      "    #initialize Tweepy API\n",
      "    api = tweepy.API(auth)\n",
      "    \n",
      "    #get the name of the spreadsheet we will write to\n",
      "    fname = '_'.join(re.findall(r\"#(\\w+)\", hashtag_phrase))\n",
      "\n",
      "    #open the spreadsheet we will write to\n",
      "    with open('%s.csv' % (fname), 'w') as file:\n",
      "\n",
      "        w = csv.writer(file)\n",
      "\n",
      "        #write header row to spreadsheet\n",
      "        w.writerow(['timestamp', 'tweet_text', 'username', 'all_hashtags', 'followers_count'])\n",
      "\n",
      "        #for each tweet matching our hashtags, write relevant info to the spreadsheet\n",
      "        for tweet in tweepy.Cursor(api.search, q=hashtag_phrase+' -filter:retweets', \\\n",
      "                                   lang=\"en\", tweet_mode='extended').items(100):\n",
      "            w.writerow([tweet.created_at, tweet.full_text.replace('\\n',' ').encode('utf-8'), tweet.user.screen_name.encode('utf-8'), [e['text'] for e in tweet._json['entities']['hashtags']], tweet.user.followers_count])\n",
      "4/16:\n",
      "consumer_key = \"EGxDfDulxJP9oHGbkwkAzNSBK\"\n",
      "consumer_secret = \"BET032qvU4Z2UOUjflTbChdpqep60jHopjkGtVEycLhofKQSPx\"\n",
      "access_token = \"2854813381-EDVXKiR6Jw3aqw6EXJI24eQ7OTu8NVek6652sBN\"\n",
      "access_token_secret = \"0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD\"\n",
      "    \n",
      "hashtag_phrase = \"edchat\"\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n",
      "4/17:\n",
      "import json\n",
      "import csv\n",
      "import tweepy\n",
      "import re\n",
      "4/18:\n",
      "\"\"\"\n",
      "INPUTS:\n",
      "    consumer_key, consumer_secret, access_token, access_token_secret: codes \n",
      "    telling twitter that we are authorized to access this data\n",
      "    hashtag_phrase: the combination of hashtags to search for\n",
      "OUTPUTS:\n",
      "    none, simply save the tweet info to a spreadsheet\n",
      "\"\"\"\n",
      "def search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase):\n",
      "    \n",
      "    #create authentication for accessing Twitter\n",
      "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "    auth.set_access_token(access_token, access_token_secret)\n",
      "\n",
      "    #initialize Tweepy API\n",
      "    api = tweepy.API(auth)\n",
      "    \n",
      "    #get the name of the spreadsheet we will write to\n",
      "    fname = '_'.join(re.findall(r\"#(\\w+)\", hashtag_phrase))\n",
      "\n",
      "    #open the spreadsheet we will write to\n",
      "    with open('%s.csv' % (fname), 'w') as file:\n",
      "\n",
      "        w = csv.writer(file)\n",
      "\n",
      "        #write header row to spreadsheet\n",
      "        w.writerow(['timestamp', 'tweet_text', 'username', 'all_hashtags', 'followers_count'])\n",
      "\n",
      "        #for each tweet matching our hashtags, write relevant info to the spreadsheet\n",
      "        for tweet in tweepy.Cursor(api.search, q=hashtag_phrase+' -filter:retweets', \\\n",
      "                                   lang=\"en\", tweet_mode='extended').items(100):\n",
      "            w.writerow([tweet.created_at, tweet.full_text.replace('\\n',' ').encode('utf-8'), tweet.user.screen_name.encode('utf-8'), [e['text'] for e in tweet._json['entities']['hashtags']], tweet.user.followers_count])\n",
      "4/19:\n",
      "consumer_key = \"EGxDfDulxJP9oHGbkwkAzNSBK\"\n",
      "consumer_secret = \"BET032qvU4Z2UOUjflTbChdpqep60jHopjkGtVEycLhofKQSPx\"\n",
      "access_token = \"2854813381-EDVXKiR6Jw3aqw6EXJI24eQ7OTu8NVek6652sBN\"\n",
      "access_token_secret = \"0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD\"\n",
      "    \n",
      "hashtag_phrase = \"edchat\"\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n",
      "4/20:\n",
      "import json\n",
      "import csv\n",
      "import tweepy\n",
      "import re\n",
      "4/21:\n",
      "\"\"\"\n",
      "INPUTS:\n",
      "    consumer_key, consumer_secret, access_token, access_token_secret: codes \n",
      "    telling twitter that we are authorized to access this data\n",
      "    hashtag_phrase: the combination of hashtags to search for\n",
      "OUTPUTS:\n",
      "    none, simply save the tweet info to a spreadsheet\n",
      "\"\"\"\n",
      "def search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase):\n",
      "    \n",
      "    #create authentication for accessing Twitter\n",
      "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "    auth.set_access_token(access_token, access_token_secret)\n",
      "\n",
      "    #initialize Tweepy API\n",
      "    api = tweepy.API(auth)\n",
      "    \n",
      "    #get the name of the spreadsheet we will write to\n",
      "    fname = '_'.join(re.findall(r\"#(\\w+)\", hashtag_phrase))\n",
      "\n",
      "    #open the spreadsheet we will write to\n",
      "    with open('file_tweets.csv' % (fname), 'w') as file:\n",
      "\n",
      "        w = csv.writer(file)\n",
      "\n",
      "        #write header row to spreadsheet\n",
      "        w.writerow(['timestamp', 'tweet_text', 'username', 'all_hashtags', 'followers_count'])\n",
      "\n",
      "        #for each tweet matching our hashtags, write relevant info to the spreadsheet\n",
      "        for tweet in tweepy.Cursor(api.search, q=hashtag_phrase+' -filter:retweets', \\\n",
      "                                   lang=\"en\", tweet_mode='extended').items(100):\n",
      "            w.writerow([tweet.created_at, tweet.full_text.replace('\\n',' ').encode('utf-8'), tweet.user.screen_name.encode('utf-8'), [e['text'] for e in tweet._json['entities']['hashtags']], tweet.user.followers_count])\n",
      "4/22:\n",
      "consumer_key = \"EGxDfDulxJP9oHGbkwkAzNSBK\"\n",
      "consumer_secret = \"BET032qvU4Z2UOUjflTbChdpqep60jHopjkGtVEycLhofKQSPx\"\n",
      "access_token = \"2854813381-EDVXKiR6Jw3aqw6EXJI24eQ7OTu8NVek6652sBN\"\n",
      "access_token_secret = \"0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD\"\n",
      "    \n",
      "hashtag_phrase = \"edchat\"\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n",
      "4/23:\n",
      "import json\n",
      "import csv\n",
      "import tweepy\n",
      "import re\n",
      "4/24:\n",
      "\"\"\"\n",
      "INPUTS:\n",
      "    consumer_key, consumer_secret, access_token, access_token_secret: codes \n",
      "    telling twitter that we are authorized to access this data\n",
      "    hashtag_phrase: the combination of hashtags to search for\n",
      "OUTPUTS:\n",
      "    none, simply save the tweet info to a spreadsheet\n",
      "\"\"\"\n",
      "def search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase):\n",
      "    \n",
      "    #create authentication for accessing Twitter\n",
      "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "    auth.set_access_token(access_token, access_token_secret)\n",
      "\n",
      "    #initialize Tweepy API\n",
      "    api = tweepy.API(auth)\n",
      "    \n",
      "    #get the name of the spreadsheet we will write to\n",
      "    fname = '_'.join(re.findall(r\"#(\\w+)\", hashtag_phrase))\n",
      "\n",
      "    #open the spreadsheet we will write to\n",
      "    with open('%s.csv' % (fname), 'w') as file:\n",
      "\n",
      "        w = csv.writer(file)\n",
      "\n",
      "        #write header row to spreadsheet\n",
      "        w.writerow(['timestamp', 'tweet_text', 'username', 'all_hashtags', 'followers_count'])\n",
      "\n",
      "        #for each tweet matching our hashtags, write relevant info to the spreadsheet\n",
      "        for tweet in tweepy.Cursor(api.search, q=hashtag_phrase+' -filter:retweets', \\\n",
      "                                   lang=\"en\", tweet_mode='extended').items(100):\n",
      "            w.writerow([tweet.created_at, tweet.full_text.replace('\\n',' ').encode('utf-8'), tweet.user.screen_name.encode('utf-8'), [e['text'] for e in tweet._json['entities']['hashtags']], tweet.user.followers_count])\n",
      "4/25:\n",
      "consumer_key = \"EGxDfDulxJP9oHGbkwkAzNSBK\"\n",
      "consumer_secret = \"BET032qvU4Z2UOUjflTbChdpqep60jHopjkGtVEycLhofKQSPx\"\n",
      "access_token = \"2854813381-EDVXKiR6Jw3aqw6EXJI24eQ7OTu8NVek6652sBN\"\n",
      "access_token_secret = \"0p7kLDqfr8p9XRLDxRF5qiLNUWximCcbMrchCr74dgcMD\"\n",
      "    \n",
      "hashtag_phrase = \"edchat\"\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n",
      " 5/1:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from jupyterthemes import jtplot\n",
      "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
      "# setting the style of the notebook to be monokai theme  \n",
      "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
      "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n",
      " 5/2: tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/Code/Twitter/spreadsheet.csv\", lines=True)\n",
      " 5/3: tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/Code/Twitter/spreadsheet.csv\")\n",
      " 5/4:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from jupyterthemes import jtplot\n",
      "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
      "# setting the style of the notebook to be monokai theme  \n",
      "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
      "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n",
      " 5/5: tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/Code/spreadsheet.csv\")\n",
      " 5/6: tweets_df\n",
      " 5/7:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from jupyterthemes import jtplot\n",
      "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
      "# setting the style of the notebook to be monokai theme  \n",
      "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
      "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n",
      " 5/8: tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/Code/spreadsheet.csv\")\n",
      " 5/9: tweets_df\n",
      "5/10:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from jupyterthemes import jtplot\n",
      "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
      "# setting the style of the notebook to be monokai theme  \n",
      "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
      "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n",
      "5/11: tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/Code/spreadsheet.csv\", skiprows=lambda x: x % 2)\n",
      "5/12: tweets_df\n",
      "5/13: tweets_df.info()\n",
      "5/14: tweets_df.describe()\n",
      " 6/1:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from jupyterthemes import jtplot\n",
      "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
      "# setting the style of the notebook to be monokai theme  \n",
      "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
      "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n",
      " 6/2: tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/Code/tweets_spreadsheet.csv\", skiprows=lambda x: x % 2)\n",
      " 6/3: tweets_df\n",
      " 6/4: tweets_df.info()\n",
      " 6/5: tweets_df.describe()\n",
      " 6/6: tweets_df['text']\n",
      " 6/7: tweets_df['tweet_text']\n",
      " 6/8: tweets_df\n",
      " 6/9: tweets_df = tweets_df.drop(['display_text_range'],axis=1)\n",
      "6/10: tweets_df\n",
      "6/11: tweets_df\n",
      "6/12: sns.heatmap(tweets_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n",
      "6/13:\n",
      "# Let's get the length of the messages\n",
      "tweets_df['length'] = tweets_df['text'].apply(len)\n",
      "6/14: tweets_df\n",
      "6/15: sns.heatmap(tweets_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n",
      "6/16:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from jupyterthemes import jtplot\n",
      "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
      "# setting the style of the notebook to be monokai theme  \n",
      "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
      "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n",
      "6/17: tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/Code/tweets_spreadsheet.csv\", skiprows=lambda x: x % 2)\n",
      "6/18: tweets_df\n",
      "6/19: tweets_df.info()\n",
      "6/20: tweets_df.describe()\n",
      "6/21: tweets_df['tweet_text']\n",
      "6/22: tweets_df\n",
      "6/23: tweets_df\n",
      "6/24: sns.heatmap(tweets_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n",
      "6/25: sns.heatmap(tweets_df.isnull())\n",
      "6/26: sns.heatmap(tweets_df)\n",
      "6/27: sns.heatmap(tweets_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n",
      "6/28: sns.heatmap(tweets_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n",
      "6/29:\n",
      "# Let's get the length of the messages\n",
      "tweets_df['length'] = tweets_df['text'].apply(len)\n",
      "6/30:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from jupyterthemes import jtplot\n",
      "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
      "# setting the style of the notebook to be monokai theme  \n",
      "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
      "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n",
      "6/31: tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/Code/tweets_spreadsheet.csv\", skiprows=lambda x: x % 2)\n",
      "6/32: tweets_df\n",
      "6/33: tweets_df.info()\n",
      "6/34: tweets_df.describe()\n",
      "6/35: tweets_df['tweet_text']\n",
      "6/36: sns.heatmap(tweets_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n",
      "6/37:\n",
      "import string\n",
      "string.punctuation\n",
      "6/38: Test = 'Good morning beautiful people :)... I am having fun learning Machine learning and AI!!'\n",
      " 7/1:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from jupyterthemes import jtplot\n",
      "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
      "# setting the style of the notebook to be monokai theme  \n",
      "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
      "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n",
      " 7/2: tweets_df = pd.read_csv('C:/Users/Dayanand Saha/Documents/OUR/Twitter/tweets_spreadsheet.csv', lines=True)\n",
      " 7/3:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from jupyterthemes import jtplot\n",
      "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
      "# setting the style of the notebook to be monokai theme  \n",
      "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
      "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n",
      " 7/4: tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/Code/tweets_spreadsheet.csv\", skiprows=lambda x: x % 2)\n",
      " 7/5: tweets_df\n",
      " 7/6: tweets_df.info()\n",
      " 7/7: tweets_df.describe()\n",
      " 7/8: tweets_df['tweet_text']\n",
      " 7/9: tweets_df['tweet_text']\n",
      "7/10: sns.heatmap(tweets_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n",
      "7/11:\n",
      "# Let's get the length of the messages\n",
      "tweets_df['length'] = tweets_df['text'].apply(len)\n",
      "7/12:\n",
      "# Let's get the length of the messages\n",
      "tweets_df['length'] = tweets_df['tweet_text'].apply(len)\n",
      "7/13: tweets_df\n",
      "7/14: tweets_df['length'].plot(bins=100, kind='hist')\n",
      "7/15: tweets_df.describe()\n",
      "7/16:\n",
      "# Let's see the shortest message \n",
      "tweets_df[tweets_df['length'] == 1]['text'].iloc[0]\n",
      "7/17: sentences = tweets_df['tweet_text'].tolist()\n",
      "7/18: sentences\n",
      "7/19: len(sentences)\n",
      "7/20: sentences_as_one_string = \" \".join(sentences)\n",
      "7/21:\n",
      "!pip install WordCloud\n",
      "from wordcloud import WordCloud\n",
      "\n",
      "plt.figure(figsize=(10,10))\n",
      "plt.imshow(WordCloud().generate(sentences_as_one_string))\n",
      "7/22:\n",
      "from wordcloud import WordCloud\n",
      "\n",
      "plt.figure(figsize=(10,10))\n",
      "plt.imshow(WordCloud().generate(sentences_as_one_string))\n",
      "7/23:\n",
      "import string\n",
      "string.punctuation\n",
      "7/24: Test = 'Good morning beautiful people :)... I am having fun learning Machine learning and AI!!'\n",
      "7/25:\n",
      "Test_punc_removed= []\n",
      "\n",
      "for char in Test:\n",
      "    if char not in string.punctuation:\n",
      "        Test_punc_removed.append(char)\n",
      "7/26:\n",
      "# Join the characters again to form the string.\n",
      "Test_punc_removed_combined = ' '.join(Test_punc_removed)\n",
      "Test_punc_removed_combined\n",
      "7/27:\n",
      "import nltk # Natural Language tool kit \n",
      "\n",
      "nltk.download('stopwords')\n",
      "7/28:\n",
      "# You have to download stopwords Package to execute this command\n",
      "from nltk.corpus import stopwords\n",
      "stopwords.words('english')\n",
      "7/29: from sklearn.feature_extraction.text import CountVectorizer\n",
      "7/30:\n",
      "# Let's define a pipeline to clean up all the messages \n",
      "# The pipeline performs the following: (1) remove punctuation, (2) remove stopwords\n",
      "\n",
      "def message_cleaning(message):\n",
      "    Test_punc_removed = [char for char in message if char not in string.punctuation]\n",
      "    Test_punc_removed_join = ''.join(Test_punc_removed)\n",
      "    Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords.words('english')]\n",
      "    return Test_punc_removed_join_clean\n",
      "7/31:\n",
      "# Let's test the newly added function\n",
      "tweets_df_clean = tweets_df['text'].apply(message_cleaning)\n",
      "7/32:\n",
      "# Let's test the newly added function\n",
      "tweets_df_clean = tweets_df['tweet_text'].apply(message_cleaning)\n",
      "7/33: print(tweets_df_clean[5]) # show the cleaned up version\n",
      "7/34: print(tweets_df['text'][5]) # show the original version\n",
      "7/35: print(tweets_df['tweet_text'][5]) # show the original version\n",
      "7/36:\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "# Define the cleaning pipeline we defined earlier\n",
      "vectorizer = CountVectorizer(analyzer = message_cleaning, dtype = 'uint8')\n",
      "tweets_countvectorizer = vectorizer.fit_transform(tweets_df['text'])\n",
      "7/37: print(vectorizer.get_feature_names())\n",
      "7/38:\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "# Define the cleaning pipeline we defined earlier\n",
      "vectorizer = CountVectorizer(analyzer = message_cleaning, dtype = 'uint8')\n",
      "tweets_countvectorizer = vectorizer.fit_transform(tweets_df['tweet_text'])\n",
      "7/39: print(vectorizer.get_feature_names())\n",
      "7/40: print(tweets_countvectorizer.toarray())\n",
      "7/41: tweets_countvectorizer.shape\n",
      "7/42: tweets = pd.DataFrame(tweets_countvectorizer.toarray())\n",
      "7/43: X = tweets\n",
      "7/44: X\n",
      "7/45: X.shape\n",
      "7/46: y.shape\n",
      "7/47:\n",
      "from sklearn.model_selection import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
      "7/48:\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "NB_classifier = MultinomialNB()\n",
      "NB_classifier.fit(X_train, y_train)\n",
      "7/49: from sklearn.metrics import classification_report, confusion_matrix\n",
      "7/50:\n",
      "# Predicting the Test set results\n",
      "y_predict_test = NB_classifier.predict(X_test)\n",
      "cm = confusion_matrix(y_test, y_predict_test)\n",
      "sns.heatmap(cm, annot=True)\n",
      " 8/1:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_excel(\"C:/Users/nic/Documents/OUR_Project/Code/scraped_tweets.xlsx\", skiprows=lambda x: x % 2)\n",
      "\n",
      "location = df['location']\n",
      " 8/2: location\n",
      " 8/3:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "!pip install geopandas\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_excel(\"C:/Users/nic/Documents/OUR_Project/Code/scraped_tweets.xlsx\", skiprows=lambda x: x % 2)\n",
      "\n",
      "location = df['location']\n",
      " 9/1:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_excel(\"C:/Users/nic/Documents/OUR_Project/Code/scraped_tweets.xlsx\", skiprows=lambda x: x % 2)\n",
      "\n",
      "location = df['location']\n",
      " 9/2:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "\n",
      "location = tweets_df['location']\n",
      " 9/3:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "\n",
      "location = tweets_df['location']\n",
      " 9/4: location\n",
      " 9/5:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "\n",
      "locations = tweets_df['location']\n",
      " 9/6: locations\n",
      " 9/7:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "\n",
      "locations = tweets_df['location'].valuecounts\n",
      " 9/8:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "\n",
      "locations = tweets_df['location'].value_counts()\n",
      " 9/9: locations\n",
      "9/10:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "9/11:\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "9/12: locations = tweets_df['location'].value_counts()\n",
      "9/13: locations = tweets_df['location'].value_counts()\n",
      "9/14:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "9/15:\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "9/16: locations = tweets_df['location'].value_counts()\n",
      "9/17: locations\n",
      "9/18:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "9/19:\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "9/20: locations = tweets_df['location'].value_counts()\n",
      "9/21: locations\n",
      "9/22:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "9/23:\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "9/24: locations = tweets_df['location'].value_counts()\n",
      "9/25: locations[locations>=10]\n",
      "9/26:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "9/27:\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "9/28:\n",
      "locations = tweets_df['location'].value_counts()\n",
      "locations[locations>=10]\n",
      "9/29:\n",
      "locations = tweets_df['location'].value_counts()\n",
      "locations[locations>=5]\n",
      "9/30:\n",
      "locations = tweets_df['location'].value_counts()\n",
      "locations[locations>=4]\n",
      "9/31:\n",
      "locations = tweets_df['location'].value_counts()\n",
      "locations[locations>=3]\n",
      "9/32:\n",
      "locations = tweets_df['location'].value_counts()\n",
      "locations[locations>=4]\n",
      "9/33:\n",
      "from geopy.geocoders import Nominatim\n",
      "geolocator = Nominatim(user_agent='twitter-analysis-cl')\n",
      "#note that user_agent is a random name\n",
      "locs = list(locs.index) #keep only the city names\n",
      "9/34:\n",
      "!pip install geopy\n",
      "from geopy.geocoders import Nominatim\n",
      "geolocator = Nominatim(user_agent='twitter-analysis-cl')\n",
      "#note that user_agent is a random name\n",
      "locs = list(locs.index) #keep only the city names\n",
      "9/35:\n",
      "locs = tweets_df['location'].value_counts()\n",
      "locs[locations>=4]\n",
      "9/36:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "9/37:\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "9/38:\n",
      "locs = tweets_df['location'].value_counts()\n",
      "locs[locations>=4]\n",
      "9/39:\n",
      "!pip install geopy\n",
      "from geopy.geocoders import Nominatim\n",
      "geolocator = Nominatim(user_agent='twitter-analysis-cl')\n",
      "#note that user_agent is a random name\n",
      "locs = list(locs.index) #keep only the city names\n",
      "9/40:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "9/41:\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "9/42:\n",
      "locs = tweets_df['location'].value_counts()\n",
      "locs[locations>=4]\n",
      "9/43:\n",
      "from geopy.geocoders import Nominatim\n",
      "geolocator = Nominatim(user_agent='twitter-analysis-cl')\n",
      "#note that user_agent is a random name\n",
      "locs = list(locs.index) #keep only the city names\n",
      "9/44:\n",
      "geolocated = list(map(lambda x: [x,geolocator.geocode(x)[1] if geolocator.geocode(x) else None],locs))\n",
      "geolocated = pd.DataFrame(geolocated)\n",
      "geolocated.columns = ['locat','latlong']\n",
      "geolocated['lat'] = geolocated.latlong.apply(lambda x: x[0])\n",
      "geolocated['lon'] = geolocated.latlong.apply(lambda x: x[1])\n",
      "geolocated.drop('latlong',axis=1, inplace=True)\n",
      "9/45:\n",
      "from geopy.geocoders import Nominatim\n",
      "geolocator = Nominatim(user_agent='twitter-analysis-cl')\n",
      "#note that user_agent is a random name\n",
      "locs = list(locs.index) #keep only the city names\n",
      "9/46:\n",
      "from geopy.geocoders import Nominatim\n",
      "geolocator = Nominatim(user_agent='twitter-analysis-cl')\n",
      "#note that user_agent is a random name\n",
      "9/47:\n",
      "geolocated = list(map(lambda x: [x,geolocator.geocode(x)[1] if geolocator.geocode(x) else None],locs))\n",
      "geolocated = pd.DataFrame(geolocated)\n",
      "geolocated.columns = ['locat','latlong']\n",
      "geolocated['lat'] = geolocated.latlong.apply(lambda x: x[0])\n",
      "geolocated['lon'] = geolocated.latlong.apply(lambda x: x[1])\n",
      "geolocated.drop('latlong',axis=1, inplace=True)\n",
      "9/48: geolocated = list(map(lambda x: [x,geolocator.geocode(x)[1] if geolocator.geocode(x) else None],locs))\n",
      "9/49:\n",
      "from geopy.geocoders import Nominatim\n",
      "from geopy.exc import GeocoderTimedOut\n",
      "\n",
      "my_address = '1600 Pennsylvania Avenue NW Washington, DC 20500'\n",
      "\n",
      "geolocator = Nominatim()\n",
      "try:\n",
      "    location = geolocator.geocode(my_address)\n",
      "    print(location.latitude, location.longitude)\n",
      "except GeocoderTimedOut as e:\n",
      "    print(\"Error: geocode failed on input %s with message %s\"%(my_address, e.message))\n",
      "9/50:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "9/51:\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "9/52:\n",
      "locs = tweets_df['location'].value_counts()\n",
      "locs[locations>=4]\n",
      "9/53: geolocated = list(map(lambda x: [x,geolocator.geocode(x, timeout=10000)[1] if geolocator.geocode(x) else None],locs))\n",
      "9/54: geolocated = list(map(lambda x: [x,geolocator.geocode(x, timeout=10000000000)[1] if geolocator.geocode(x) else None],locs))\n",
      "9/55: geolocated = list(map(lambda x: [x,geolocator.geocode(x, timeout=10000000)[1] if geolocator.geocode(x) else None],locs))\n",
      "9/56: geolocated = list(map(lambda x: [x,geolocator.geocode(x, timeout=1000000)[1] if geolocator.geocode(x) else None],locs))\n",
      "9/57: geolocated = list(map(lambda x: [x,geolocator.geocode(x, timeout=None)[1] if geolocator.geocode(x) else None],locs))\n",
      "9/58: tweets_df['location'] = tweets_df['locaddress'].apply(geocode)\n",
      "9/59:\n",
      "from geopy.exc import GeocoderTimedOut\n",
      "from geopy.geocoders import Nominatim\n",
      "   \n",
      "# declare an empty list to store\n",
      "# latitude and longitude of values \n",
      "# of city column\n",
      "longitude = []\n",
      "latitude = []\n",
      "   \n",
      "# function to find the coordinate\n",
      "# of a given city \n",
      "def findGeocode(city):\n",
      "       \n",
      "    # try and catch is used to overcome\n",
      "    # the exception thrown by geolocator\n",
      "    # using geocodertimedout  \n",
      "    try:\n",
      "          \n",
      "        # Specify the user_agent as your\n",
      "        # app name it should not be none\n",
      "        geolocator = Nominatim(user_agent=\"your_app_name\")\n",
      "          \n",
      "        return geolocator.geocode(city)\n",
      "      \n",
      "    except GeocoderTimedOut:\n",
      "          \n",
      "        return findGeocode(city)    \n",
      "  \n",
      "# each value from city column\n",
      "# will be fetched and sent to\n",
      "# function find_geocode   \n",
      "for i in (df[\"City\"]):\n",
      "      \n",
      "    if findGeocode(i) != None:\n",
      "           \n",
      "        loc = findGeocode(i)\n",
      "          \n",
      "        # coordinates returned from \n",
      "        # function is stored into\n",
      "        # two separate list\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "       \n",
      "    # if coordinate for a city not\n",
      "    # found, insert \"NaN\" indicating \n",
      "    # missing value \n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "9/60:\n",
      "from geopy.exc import GeocoderTimedOut\n",
      "from geopy.geocoders import Nominatim\n",
      "   \n",
      "# declare an empty list to store\n",
      "# latitude and longitude of values \n",
      "# of city column\n",
      "longitude = []\n",
      "latitude = []\n",
      "   \n",
      "# function to find the coordinate\n",
      "# of a given city \n",
      "def findGeocode(city):\n",
      "       \n",
      "    # try and catch is used to overcome\n",
      "    # the exception thrown by geolocator\n",
      "    # using geocodertimedout  \n",
      "    try:\n",
      "          \n",
      "        # Specify the user_agent as your\n",
      "        # app name it should not be none\n",
      "        geolocator = Nominatim(user_agent=\"your_app_name\")\n",
      "          \n",
      "        return geolocator.geocode(city)\n",
      "      \n",
      "    except GeocoderTimedOut:\n",
      "          \n",
      "        return findGeocode(city)    \n",
      "  \n",
      "# each value from city column\n",
      "# will be fetched and sent to\n",
      "# function find_geocode   \n",
      "for i in (tweets_df['location']):\n",
      "      \n",
      "    if findGeocode(i) != None:\n",
      "           \n",
      "        loc = findGeocode(i)\n",
      "          \n",
      "        # coordinates returned from \n",
      "        # function is stored into\n",
      "        # two separate list\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "       \n",
      "    # if coordinate for a city not\n",
      "    # found, insert \"NaN\" indicating \n",
      "    # missing value \n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "9/61:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "9/62:\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "9/63:\n",
      "locs = tweets_df['location'].value_counts()\n",
      "locs[locations>=4]\n",
      "9/64:\n",
      "from geopy.exc import GeocoderTimedOut\n",
      "from geopy.geocoders import Nominatim\n",
      "   \n",
      "# declare an empty list to store\n",
      "# latitude and longitude of values \n",
      "# of city column\n",
      "longitude = []\n",
      "latitude = []\n",
      "   \n",
      "# function to find the coordinate\n",
      "# of a given city \n",
      "def findGeocode(city):\n",
      "       \n",
      "    # try and catch is used to overcome\n",
      "    # the exception thrown by geolocator\n",
      "    # using geocodertimedout  \n",
      "    try:\n",
      "          \n",
      "        # Specify the user_agent as your\n",
      "        # app name it should not be none\n",
      "        geolocator = Nominatim(user_agent=\"your_app_name\")\n",
      "          \n",
      "        return geolocator.geocode(city)\n",
      "      \n",
      "    except GeocoderTimedOut:\n",
      "          \n",
      "        return findGeocode(city)    \n",
      "  \n",
      "# each value from city column\n",
      "# will be fetched and sent to\n",
      "# function find_geocode   \n",
      "for i in (tweets_df['location']):\n",
      "      \n",
      "    if findGeocode(i) != None:\n",
      "           \n",
      "        loc = findGeocode(i)\n",
      "          \n",
      "        # coordinates returned from \n",
      "        # function is stored into\n",
      "        # two separate list\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "       \n",
      "    # if coordinate for a city not\n",
      "    # found, insert \"NaN\" indicating \n",
      "    # missing value \n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "9/65:\n",
      "from geopy.geocoders import Nominatim\n",
      "address='Nagpur'\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "location = geolocator.geocode(address)\n",
      "print(location.address)\n",
      "print((location.latitude, location.longitude))\n",
      "9/66:\n",
      "from geopy.exc import GeocoderTimedOut\n",
      "from geopy.geocoders import Nominatim\n",
      "   \n",
      "# declare an empty list to store\n",
      "# latitude and longitude of values \n",
      "# of city column\n",
      "longitude = []\n",
      "latitude = []\n",
      "   \n",
      "# function to find the coordinate\n",
      "# of a given city \n",
      "def findGeocode(city):\n",
      "       \n",
      "    # try and catch is used to overcome\n",
      "    # the exception thrown by geolocator\n",
      "    # using geocodertimedout  \n",
      "    try:\n",
      "          \n",
      "        # Specify the user_agent as your\n",
      "        # app name it should not be none\n",
      "        geolocator = Nominatim(user_agent=\"your_app_name\")\n",
      "          \n",
      "        return geolocator.geocode(city)\n",
      "      \n",
      "    except GeocoderTimedOut:\n",
      "          \n",
      "        return findGeocode(city)    \n",
      "  \n",
      "# each value from city column\n",
      "# will be fetched and sent to\n",
      "# function find_geocode   \n",
      "for i in (tweets_df['location']):\n",
      "      \n",
      "    if findGeocode(i) != None:\n",
      "           \n",
      "        loc = findGeocode(i)\n",
      "          \n",
      "        # coordinates returned from \n",
      "        # function is stored into\n",
      "        # two separate list\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "       \n",
      "    # if coordinate for a city not\n",
      "    # found, insert \"NaN\" indicating \n",
      "    # missing value \n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "9/67:\n",
      "from geopy.exc import GeocoderTimedOut\n",
      "from geopy.geocoders import Nominatim\n",
      "   \n",
      "# declare an empty list to store\n",
      "# latitude and longitude of values \n",
      "# of city column\n",
      "longitude = []\n",
      "latitude = []\n",
      "   \n",
      "# function to find the coordinate\n",
      "# of a given city \n",
      "def findGeocode(city):\n",
      "       \n",
      "    # try and catch is used to overcome\n",
      "    # the exception thrown by geolocator\n",
      "    # using geocodertimedout  \n",
      "    try:\n",
      "          \n",
      "        # Specify the user_agent as your\n",
      "        # app name it should not be none\n",
      "        geolocator = Nominatim(user_agent=\"http\")\n",
      "          \n",
      "        return geolocator.geocode(city)\n",
      "      \n",
      "    except GeocoderTimedOut:\n",
      "          \n",
      "        return findGeocode(city)    \n",
      "\n",
      "# each value from city column will be fetched and sent to function find_geocode   \n",
      "for i in (tweets_df['location']):\n",
      "      \n",
      "    if findGeocode(i) != None:\n",
      "           \n",
      "        loc = findGeocode(i)\n",
      "          \n",
      "        # coordinates returned from \n",
      "        # function is stored into\n",
      "        # two separate list\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "       \n",
      "    # if coordinate for a city not\n",
      "    # found, insert \"NaN\" indicating \n",
      "    # missing value \n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "9/68:\n",
      "locs = tweets_df['location'].value_counts()\n",
      "locs[locations>=4]\n",
      "9/69:\n",
      "from geopy.exc import GeocoderTimedOut\n",
      "from geopy.geocoders import Nominatim\n",
      "   \n",
      "# declare an empty list to store\n",
      "# latitude and longitude of values \n",
      "# of city column\n",
      "longitude = []\n",
      "latitude = []\n",
      "   \n",
      "# function to find the coordinate\n",
      "# of a given city \n",
      "def findGeocode(city):\n",
      "       \n",
      "    # try and catch is used to overcome\n",
      "    # the exception thrown by geolocator\n",
      "    # using geocodertimedout  \n",
      "    try:\n",
      "          \n",
      "        # Specify the user_agent as your\n",
      "        # app name it should not be none\n",
      "        geolocator = Nominatim(user_agent=\"debsa2000@gmail.com\")\n",
      "          \n",
      "        return geolocator.geocode(city)\n",
      "      \n",
      "    except GeocoderTimedOut:\n",
      "          \n",
      "        return findGeocode(city)    \n",
      "\n",
      "# each value from city column will be fetched and sent to function find_geocode   \n",
      "for i in (tweets_df['location']):\n",
      "      \n",
      "    if findGeocode(i) != None:\n",
      "           \n",
      "        loc = findGeocode(i)\n",
      "          \n",
      "        # coordinates returned from \n",
      "        # function is stored into\n",
      "        # two separate list\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "       \n",
      "    # if coordinate for a city not\n",
      "    # found, insert \"NaN\" indicating \n",
      "    # missing value \n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "9/70:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "address='Barcelona'\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "location = geolocator.geocode(address)\n",
      "print(location.address)\n",
      "print((location.latitude, location.longitude))\n",
      "#Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "#(41.3828939, 2.1774322)\n",
      "9/71:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# each value from city column will be fetched and sent to function find_geocode   \n",
      "for i in (tweets_df['location']):\n",
      "      \n",
      "   # if findGeocode(i) != None:\n",
      "        loc = geolocator.geocode(i)\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "   # else:\n",
      "      #  latitude.append(np.nan)\n",
      "      #  longitude.append(np.nan)\n",
      "        \n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "9/72:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# each value from city column will be fetched and sent to function find_geocode   \n",
      "for i in (tweets_df['location']):\n",
      "      \n",
      "   # if findGeocode(i) != None:\n",
      "        loc = geolocator.geocode(i)\n",
      "#         latitude.append(loc.latitude)\n",
      "#         longitude.append(loc.longitude)\n",
      "   # else:\n",
      "      #  latitude.append(np.nan)\n",
      "      #  longitude.append(np.nan)\n",
      "        \n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "9/73:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# each value from city column will be fetched and sent to function find_geocode   \n",
      "for i in (tweets_df['location']):\n",
      "      \n",
      "   # if findGeocode(i) != None:\n",
      "        loc = geolocator.geocode(i)\n",
      "#         latitude.append(loc.latitude)\n",
      "#         longitude.append(loc.longitude)\n",
      "   # else:\n",
      "      #  latitude.append(np.nan)\n",
      "      #  longitude.append(np.nan)\n",
      "        \n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "9/74:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "\n",
      "# for i in (tweets_df['location']):\n",
      "      \n",
      "#    # if findGeocode(i) != None:\n",
      "#         loc = geolocator.geocode(i)\n",
      "#         latitude.append(loc.latitude)\n",
      "#         longitude.append(loc.longitude)\n",
      "#    # else:\n",
      "#       #  latitude.append(np.nan)\n",
      "#       #  longitude.append(np.nan)\n",
      "        \n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "9/75:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "\n",
      "for i in (tweets_df['location']):\n",
      "    if geolocator.geocode(i) != None:\n",
      "        loc = geolocator.geocode(i)\n",
      "#         latitude.append(loc.latitude)\n",
      "#         longitude.append(loc.longitude)\n",
      "#    # else:\n",
      "#       #  latitude.append(np.nan)\n",
      "#       #  longitude.append(np.nan)\n",
      "        \n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "9/76:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "\n",
      "for i in (tweets_df['location']):\n",
      "    if(i != None):\n",
      "        if geolocator.geocode(i) != None:\n",
      "            loc = geolocator.geocode(i)\n",
      "            latitude.append(loc.latitude)\n",
      "            longitude.append(loc.longitude)\n",
      "#    # else:\n",
      "#       #  latitude.append(np.nan)\n",
      "#       #  longitude.append(np.nan)\n",
      "        \n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "9/77:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "address='Barcelona'\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "location = geolocator.geocode(address)\n",
      "print(location.address)\n",
      "print((location.latitude, location.longitude))\n",
      "#Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "#(41.3828939, 2.1774322)\n",
      "9/78:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "address='Barcelona'\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "location = geolocator.geocode(address)\n",
      "print(location.address)\n",
      "print((location.latitude, location.longitude))\n",
      "#Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "#(41.3828939, 2.1774322)\n",
      "9/79:\n",
      "# now add this column to dataframe\n",
      "tweets_df[\"Longitude\"] = longitude\n",
      "tweets_df[\"Latitude\"] = latitude\n",
      "  \n",
      "tweets_df\n",
      "9/80:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "9/81:\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "9/82:\n",
      "locs = tweets_df['location'].value_counts()\n",
      "locs[locations>=4]\n",
      "9/83:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "address='Barcelona'\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "location = geolocator.geocode(address)\n",
      "print(location.address)\n",
      "print((location.latitude, location.longitude))\n",
      "#Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "#(41.3828939, 2.1774322)\n",
      "9/84:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    address=i\n",
      "    geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "    if geolocator.geocode(address) != None:\n",
      "        loc = geolocator.geocode(address)\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "9/85:\n",
      "# now add this column to dataframe\n",
      "tweets_df[\"Longitude\"] = longitude\n",
      "tweets_df[\"Latitude\"] = latitude\n",
      "  \n",
      "tweets_df\n",
      "9/86: longitude\n",
      "9/87: longitudes\n",
      "9/88: longitude\n",
      "9/89:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    if(i==np.nan):\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "    else:\n",
      "        address=i\n",
      "        geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "        if geolocator.geocode(address) != None:\n",
      "            loc = geolocator.geocode(address)\n",
      "            latitude.append(loc.latitude)\n",
      "            longitude.append(loc.longitude)\n",
      "        else:\n",
      "            latitude.append(np.nan)\n",
      "            longitude.append(np.nan)\n",
      "9/90:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    if(i==np.nan):\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "#     else:\n",
      "#         address=i\n",
      "#         geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "#         if geolocator.geocode(address) != None:\n",
      "#             loc = geolocator.geocode(address)\n",
      "#             latitude.append(loc.latitude)\n",
      "#             longitude.append(loc.longitude)\n",
      "#         else:\n",
      "#             latitude.append(np.nan)\n",
      "#             longitude.append(np.nan)\n",
      "9/91:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    if(i==np.nan):\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "#     else:\n",
      "#         address=i\n",
      "#         geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "#         if geolocator.geocode(address) != None:\n",
      "#             loc = geolocator.geocode(address)\n",
      "#             latitude.append(loc.latitude)\n",
      "#             longitude.append(loc.longitude)\n",
      "#         else:\n",
      "#             latitude.append(np.nan)\n",
      "#             longitude.append(np.nan)\n",
      "9/92:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    if(i==np.nan):\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "    else:\n",
      "        address=i\n",
      "        geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "        if geolocator.geocode(address) != None:\n",
      "            loc = geolocator.geocode(address)\n",
      "            latitude.append(loc.latitude)\n",
      "            longitude.append(loc.longitude)\n",
      "        else:\n",
      "            latitude.append(np.nan)\n",
      "            longitude.append(np.nan)\n",
      "9/93:\n",
      "# now add this column to dataframe\n",
      "tweets_df[\"Longitude\"] = longitude\n",
      "tweets_df[\"Latitude\"] = latitude\n",
      "  \n",
      "tweets_df\n",
      "9/94:\n",
      "# now add this column to dataframe\n",
      "tweets_df[\"Longitude\"] = longitude\n",
      "tweets_df[\"Latitude\"] = latitude\n",
      "  \n",
      "tweets_df\n",
      "9/95:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    address=i\n",
      "    geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "    if geolocator.geocode(address) != None:\n",
      "        loc = geolocator.geocode(address)\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "9/96:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "9/97:\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "9/98:\n",
      "locs = tweets_df['location'].value_counts()\n",
      "locs[locations>=4]\n",
      "9/99:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    address=i\n",
      "    geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "    if geolocator.geocode(address) != None:\n",
      "        loc = geolocator.geocode(address)\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "9/100:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    address=i\n",
      "    geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "    if geolocator.geocode(address) != None:\n",
      "        loc = geolocator.geocode(address)\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "9/101:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    address=i\n",
      "    geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "    if geolocator.geocode(address) != None:\n",
      "        loc = geolocator.geocode(address)\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "9/102:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "address='Barcelona'\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "location = geolocator.geocode(address)\n",
      "print(location.address)\n",
      "print((location.latitude, location.longitude))\n",
      "#Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "#(41.3828939, 2.1774322)\n",
      "   1:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "   2:\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "   3:\n",
      "locs = tweets_df['location'].value_counts()\n",
      "locs[locations>=4]\n",
      "   4:\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import geopandas as gpd\n",
      "from shapely.geometry import Point, Polygon\n",
      "   5:\n",
      "# Reading dataset\n",
      "tweets_df = pd.read_csv(\"C:/Users/nic/Documents/OUR_Project/new.csv\", skiprows=lambda x: x % 2)\n",
      "   6:\n",
      "locs = tweets_df['location'].value_counts()\n",
      "locs[locs>=4]\n",
      "   7:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "for i in (tweets\n",
      "          -df[\"City\"]):\n",
      "address='Barcelona'\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "location = geolocator.geocode(address)\n",
      "print(location.address)\n",
      "print((location.latitude, location.longitude))\n",
      "#Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "#(41.3828939, 2.1774322)\n",
      "   8:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "# for i in (tweets_df[\"City\"]):\n",
      "address='Barcelona'\n",
      "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "location = geolocator.geocode(address)\n",
      "print(location.address)\n",
      "print((location.latitude, location.longitude))\n",
      "#Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "#(41.3828939, 2.1774322)\n",
      "   9:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "geolocator = Nominatim(user_agent=\"Debanjali\")\n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    coordinates = geolocator.geocode(i)\n",
      "    if coordinates != None:\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "\n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "  10:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "geolocator = Nominatim(user_agent=\"Debanjali\")\n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    coordinates = geolocator.geocode(i)\n",
      "    if coordinates != None:\n",
      "        latitude.append(coordinates.latitude)\n",
      "        longitude.append(coordinates.longitude)\n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "\n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "  11:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "geolocator = Nominatim(user_agent=\"Debanjali\")\n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    coordinates = geolocator.geocode(i)\n",
      "#     if coordinates != None:\n",
      "#         latitude.append(coordinates.latitude)\n",
      "#         longitude.append(coordinates.longitude)\n",
      "#     else:\n",
      "#         latitude.append(np.nan)\n",
      "#         longitude.append(np.nan)\n",
      "\n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "  12:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "def findGeocode(city):\n",
      "    try:\n",
      "        return geolocator.geocode(city)\n",
      "    except GeocoderTimedOut:\n",
      "        return findGeocode(city)    \n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    if findGeocode(i) != None:\n",
      "        loc = findGeocode(i)\n",
      "        latitude.append(loc.latitude)\n",
      "        longitude.append(loc.longitude)\n",
      "    else:\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "        \n",
      "        \n",
      "# geolocator = Nominatim(user_agent=\"Debanjali\")\n",
      "\n",
      "# for i in (tweets_df[\"location\"]):\n",
      "#     coordinates = geolocator.geocode(i)\n",
      "#     if coordinates != None:\n",
      "#         latitude.append(coordinates.latitude)\n",
      "#         longitude.append(coordinates.longitude)\n",
      "#     else:\n",
      "#         latitude.append(np.nan)\n",
      "#         longitude.append(np.nan)\n",
      "\n",
      "# address='Barcelona'\n",
      "# geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "# location = geolocator.geocode(address)\n",
      "# print(location.address)\n",
      "# print((location.latitude, location.longitude))\n",
      "# #Barcelona, Barcelons, Barcelona, Catalunya, 08001, Espaa\n",
      "# #(41.3828939, 2.1774322)\n",
      "  13:\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "longitude = []\n",
      "latitude = []\n",
      "\n",
      "for i in (tweets_df[\"location\"]):\n",
      "    if(i==np.nan):\n",
      "        latitude.append(np.nan)\n",
      "        longitude.append(np.nan)\n",
      "    else:\n",
      "        address=i\n",
      "        geolocator = Nominatim(user_agent=\"Your_Name\")\n",
      "        if geolocator.geocode(address) != None:\n",
      "            loc = geolocator.geocode(address)\n",
      "            latitude.append(loc.latitude)\n",
      "            longitude.append(loc.longitude)\n",
      "        else:\n",
      "            latitude.append(np.nan)\n",
      "            longitude.append(np.nan)\n",
      "  14: %history -g\n"
     ]
    }
   ],
   "source": [
    "%history -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec812a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
